{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-fb48ed91b0ab>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-fb48ed91b0ab>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1. 判断题\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1. 判断题\n",
    "    [x] LMS算法中的神经元与Rosenblatt感知器的区别是前者激活函数为线性激活函数，后者为阶跃函数。\n",
    "    [ ] LSM算法使用批量梯度下降法优化代价函数并求解模型参数。\n",
    "    [x] 最速下降法中的学习率通常是大约0小于1的值。\n",
    "    [x] 小批量学习中学习率应该设置小一些（相比于批量学习）以保证稳定性。\n",
    "    [ ] 在线算法是指从连续产生样本的数据流中抽取样本，在训练时取小批量样本进行。\n",
    "    [ ] 梯度下降法和牛顿法都是一阶优化法。\n",
    "    [x] 使用梯度下降法等优化算法求解模型参数时，往往首先需要打乱原始样本数据的顺序。\n",
    "    [x] 通常的，小批量算法比批量算法运算迭代一次所需的计算机资源更少。\n",
    "2. 选择题\n",
    "    关于最小均方算法的说法正确的是（ ABCD ）\n",
    "    A. 模型由一个神经元构成。\n",
    "    B. 使用优化法可得到模型参数。\n",
    "    C. 模型参数的初始值是随机的。\n",
    "    D. 最小均方算法在更新参数时学习率过大可能导致模型无法收敛。\n",
    "3. 简答题\n",
    "    以下任务分别使用了哪种优化法（批量、小批量、随机/在线优化法）\n",
    "        [小批量] 从手写数字数据集MNIST中每次随机抽取32个样本完成一次训练。\n",
    "        [在线] 根据用户对购物网站访问实时生成的数据，训练用户对物品偏好的算法。\n",
    "        [批量] 从搜集到的100个样本的房价数据集中训练模型估计房价，优化时每次取100个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  4. 代码练习\n",
    "def model(X, W, b):\n",
    "    '''模型\n",
    "\n",
    "    Args:\n",
    "        X: 模型输入向量\n",
    "        W: 模型连接权重向量\n",
    "        b: 模型的偏置值\n",
    "\n",
    "    Return:\n",
    "        返回模型输出结果\n",
    "    '''\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return np.sum(X * W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_train = 100\n",
    "num_test = 10\n",
    "\n",
    "# 制作数据集\n",
    "data = make_regression(n_samples=num_train, n_features=2)\n",
    "# 可视化数据集\n",
    "plt.figure(figsize=[12, 4], dpi=100)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data[0][:, 0], data[0][:, 1], 1)\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')\n",
    "plt.subplot(1, 2, 2)\n",
    "x = PCA(n_components=1).fit_transform(data[0])\n",
    "plt.scatter(x, data[1], 1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "# 将数据集分割成为训练集与测试集\n",
    "# 并将数据集转成可迭代对象\n",
    "train_x, test_x, train_y, test_y = [itertools.cycle(i) for i in train_test_split(data[0], data[1], test_size=num_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'losses')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_steps = 100   # 训练次数\n",
    "lr =0.01                    # 学习率\n",
    "summary_step = 20   # 摘要频率 \n",
    "summary = []            # 摘要\n",
    "\n",
    "W = np.random.randn(2)  # 初始化连接权重\n",
    "b = 0                             # 初始化偏置值\n",
    "for i in range(train_steps):\n",
    "    # 摘要\n",
    "    if i % summary_step == 0:\n",
    "        tmp = []\n",
    "        for j in range(num_test):\n",
    "            X = next(test_x)\n",
    "            label = next(test_y)\n",
    "            out = model(X, W, b)\n",
    "            tmp.append(np.array([label, out]))\n",
    "            \n",
    "        tmp = np.array(tmp)\n",
    "        # 计算均方误差代价\n",
    "        loss = mse(tmp[:, 0], tmp[:, 1])\n",
    "        summary.append(np.array([i + 1, loss]))\n",
    "\n",
    "    # 获得一个样本，并输入模型得到模型输出结果\n",
    "    X = next(train_x)\n",
    "    label = next(train_y)\n",
    "    out = model(X, W, b)\n",
    "    \n",
    "    # 计算偏导数并更新模型参数\n",
    "    dW = -X * (label - out)\n",
    "    W = W - lr * dW\n",
    "    db = -1 * (label - out)\n",
    "    b = b - lr * db\n",
    "\n",
    "# 可视化摘要\n",
    "summary = np.array(summary)    \n",
    "plt.figure(figsize=[8, 3], dpi=100)\n",
    "plt.plot(summary[:, 0], summary[:, 1])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('losses')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
